#!/usr/bin/env python
import numpy as np
import matplotlib.pyplot as plt
from astropy.table import Table
import scipy.optimize as optimize
import fitsio
from time import time as clock
from os.path import join, exists, abspath, basename

from halophot.halo_tools import *

from argparse import ArgumentParser

import matplotlib as mpl

mpl.style.use('seaborn-colorblind')

#To make sure we have always the same matplotlib settings
#(the ones in comments are the ipython notebook settings)

mpl.rcParams['figure.figsize']=(8.0,6.0)    #(6.0,4.0)
mpl.rcParams['font.size']=18               #10 
mpl.rcParams['savefig.dpi']= 200             #72 
mpl.rcParams['axes.labelsize'] = 16
mpl.rcParams['axes.labelsize'] = 16
mpl.rcParams['xtick.labelsize'] = 12
mpl.rcParams['ytick.labelsize'] = 12


'''-----------------------------------------------------------------
halo

This executable Python script allows you to detrend any single halo
photometry.

An example call is 

halo ktwo200007768-c04_lpd-targ.fits --data-dir /home/ben/Data/kepler/halo/ --name atlas -c 4 --do-plot -sub 8
-----------------------------------------------------------------'''

if __name__ == '__main__':
	ap = ArgumentParser(description='halophot: K2 halo photometry with total variation.')
	ap.add_argument('fname', type=str, help='Input target pixel file name.')
	ap.add_argument('--data-dir', default=None, type=str)
	ap.add_argument('--name', default='test',type=str,help='Target name')
	ap.add_argument('-c', '--campaign', metavar='C',default=4, type=int, 
		help='Campaign number')
	ap.add_argument('-o', '--order', metavar='O', type=int,default=1, 
		help='TV Order: \1 for gradient, 2 for concavity')
	ap.add_argument('-sub',  type=int,default=1, help='Subsampling parameter')
	ap.add_argument('-maxiter',  type=int,default=151, help='Maximum # iterations')
	ap.add_argument('--splits', default=None, type=lambda s:fromstring(s.strip('[]'), 
		sep=','), help='List of time values for kernel splits')
	ap.add_argument('--quiet', action='store_true', default=False, 
		help='suppress messages')
	ap.add_argument('--save-dir', default='.', 
		help='The directory to save the output file in')
	ap.add_argument('--do-plot', action = 'store_true', default = False, \
					help = 'produce plots')
	ap.add_argument('--do-split', action = 'store_true', default = False, \
					help = 'produce plots')
	ap.add_argument('--random-init', action = 'store_true', default = False, \
					help = 'initialize search with random seed')

	args = ap.parse_args()

	csplits = {4: [550,2200]}

	if args.splits is None:
		splits = csplits[args.campaign]
	else:
		splits = args.splits

	if not exists(args.save_dir):
		logger.error("Error: the save directory {:s} doesn't exists".format(args.save_dir), file=sys.stderr)
		exit(errno.ENOENT)

	### first load your data
	fname = args.data_dir + args.fname
	tpf, ts = read_tpf(fname)
	print 'Data loaded!'

	if args.do_split:
		print 'First doing one run to establish weights'

		tpf, newts, weights, weightmap = do_lc(tpf,ts,(None,None),args.sub, args.order,
			maxiter=args.maxiter,random_init=args.random_init)

		'Splitting at',splits
		# do first segment
		tpf1, ts1, w1, wm1 = do_lc(tpf, ts, (None,splits[0]), args.sub, args.order,
			maxiter=args.maxiter,w_init=weights,random_init=args.random_init)

		# do others
		tpf2, ts2, w2, wm2 = do_lc(tpf, ts, (splits[0],splits[1]), args.sub, args.order,
			maxiter=args.maxiter,w_init=weights,random_init=args.random_init)
		tpf3, ts3, w3, weightmap = do_lc(tpf, ts, (splits[1],None), args.sub, args.order,
			maxiter=args.maxiter,w_init=weights,random_init=args.random_init)

		## now stitch these

		newts = stitch([ts1,ts2,ts3])
	else:
		print 'Not splitting'
		tpf, newts, weights, weightmap = do_lc(tpf,ts,(None,None),args.sub, args.order,
			maxiter=args.maxiter,random_init=args.random_init)

	time, opt_lc = newts['time'][:], newts['corr_flux'][:]

	tv1 = diff_1(opt_lc/np.nanmedian(opt_lc))/float(np.size(opt_lc))
	tv2 = diff_2(opt_lc/np.nanmedian(opt_lc))/float(np.size(opt_lc))

	print 'Total variation per point (first order)',tv1

	print 'Total variation per point (second order)',tv2

	### save your new light curve!

	norm = np.size(weightmap)
	weightmap = np.ma.array(weightmap,mask=np.isnan(weightmap))
	hdus = astropy.io.fits.HDUList(weightmap)
	hdus.extend(newts)

	hdus.writeto('%s/%shalo_lc_o%s.fits' % (args.save_dir,args.name,args.order),overwrite=True)


	# newts.write('%s/%shalo_lc_o%s.fits' % (args.save_dir,args.name,args.order),overwrite=True)
	print 'Saved halo-corrected light curve to %s/%shalo_lc_o%s.fits' % (args.save_dir,args.name,args.order)

	if args.do_plot:
		plt.figure(1)
		plt.clf()
		plt.plot(newts['time'],opt_lc/np.nanmedian(opt_lc),'-')
		plt.xlabel('Time')
		plt.ylabel('Relative Flux')
		plt.title(args.name)
		plt.savefig('%s/%shalo_lc_o%s.png' % (args.save_dir,args.name,args.order))
		plt.show()
		print 'Saved halo-corrected light curve plot to %s/%shalo_lc_o%s.png' % (args.save_dir,args.name,args.order)

		plt.figure(2)
		plt.clf()
		cmap = mpl.cm.seismic
		cmap.set_bad('k',1.)
		plt.imshow(np.log10(weightmap.T*norm),cmap=cmap,
			interpolation='None',origin='lower')
		plt.colorbar()
		plt.savefig('%s/%s_weightmap_o%s.png' % (args.save_dir,args.name,args.order))
		plt.show()
		print 'Weight map saved to %s/%s_weightmap_o%s_sub%s.png' % (args.save_dir,args.name,args.order,args.sub)